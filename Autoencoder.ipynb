{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843b27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib, json, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d2ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1638568, 50), (409643, 50), (834347, 50))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the saved preprocessed data\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "processed_path = os.path.join(project_root, \"Data\", \"Processed\")\n",
    "\n",
    "x_train = joblib.load(os.path.join(processed_path, \"train_scaled.pkl\"))\n",
    "x_val = joblib.load(os.path.join(processed_path, \"val_scaled.pkl\"))\n",
    "x_test = joblib.load(os.path.join(processed_path, \"test_scaled.pkl\"))\n",
    "y_test = joblib.load(os.path.join(processed_path, \"test_labels.pkl\"))\n",
    "\n",
    "\n",
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec702291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scaler so that any new \n",
    "# traffic data (later) will be scaled \n",
    "# the exact same way as the trained data\n",
    "\n",
    "scaler_path = os.path.join(processed_path, \"scaler_cicids.pkl\")\n",
    "\n",
    "if os.path.exists(scaler_path):\n",
    "    scaler = joblib.load(scaler_path)\n",
    "else:\n",
    "    scaler = None\n",
    "    print(\"scaler not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfecdaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ae_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bottleneck_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ae_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ae_input (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_32 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_16 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_12 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m204\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bottleneck_16 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_12 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m204\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_16 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_32 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ae_output (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m1,650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,178</span> (20.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,178\u001b[0m (20.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,178</span> (20.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,178\u001b[0m (20.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BUILD THE AUTOENCODER\n",
    "\n",
    "# ensure same results every time\n",
    "seed = 55\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "\n",
    "\n",
    "input_dim = 50  # one input neuron for each feature\n",
    "\n",
    "input_layer = Input(shape=(input_dim,), name=\"ae_input\")   #entry point\n",
    "\n",
    "# ENCODER (compression)\n",
    "enc = Dense(32, activation='relu' , name=\"enc_dense_32\")(input_layer)    \n",
    "enc = Dense(16, activation='relu' , name=\"enc_dense_16\")(enc)\n",
    "enc = Dense(12, activation='relu' , name=\"enc_dense_12\")(enc)\n",
    "bottleneck = Dense(16, activation='relu' , name=\"bottleneck_16\")(enc)\n",
    "# each layer takes the previous layer's output and transforms it to a smaller number of neurons\n",
    "# ,this compresses the information\n",
    "# ,the final layer is the compressed version the encoder learns to use for reconstructing the data\n",
    "\n",
    "\n",
    "# DECODER (reconstruction)\n",
    "dec = Dense(12, activation='relu' , name=\"dec_dense_12\")(bottleneck)\n",
    "dec = Dense(16, activation='relu', name=\"dec_dense_16\")(dec)\n",
    "dec = Dense(32, activation='relu', name=\"dec_dense_32\")(dec)\n",
    "\n",
    "# these layers start reconstructing the data back to the original 50 dimension\n",
    "# basically the encoder extracts patterns, decoder just rebuilds\n",
    "\n",
    "output_layer = Dense(input_dim, activation='linear', name=\"ae_output\")(dec)\n",
    "\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer, name=\"Autoencoder\")\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30481a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.1848 - val_loss: 0.0711\n",
      "Epoch 2/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0564 - val_loss: 0.0470\n",
      "Epoch 3/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0425 - val_loss: 0.0390\n",
      "Epoch 4/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0365 - val_loss: 0.0345\n",
      "Epoch 5/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0328 - val_loss: 0.0313\n",
      "Epoch 6/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0301 - val_loss: 0.0290\n",
      "Epoch 7/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0279 - val_loss: 0.0270\n",
      "Epoch 8/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0262 - val_loss: 0.0253\n",
      "Epoch 9/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0246 - val_loss: 0.0239\n",
      "Epoch 10/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0233 - val_loss: 0.0228\n",
      "Epoch 11/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0224 - val_loss: 0.0219\n",
      "Epoch 12/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0216 - val_loss: 0.0213\n",
      "Epoch 13/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0210 - val_loss: 0.0206\n",
      "Epoch 14/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0204 - val_loss: 0.0201\n",
      "Epoch 15/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0199 - val_loss: 0.0196\n",
      "Epoch 16/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 17/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0188 - val_loss: 0.0186\n",
      "Epoch 18/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 19/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0180 - val_loss: 0.0178\n",
      "Epoch 20/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0176 - val_loss: 0.0175\n",
      "Epoch 21/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0173 - val_loss: 0.0172\n",
      "Epoch 22/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0170 - val_loss: 0.0170\n",
      "Epoch 23/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 24/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 25/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 26/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 27/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0161 - val_loss: 0.0160\n",
      "Epoch 28/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0159 - val_loss: 0.0159\n",
      "Epoch 29/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 30/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0156 - val_loss: 0.0156\n",
      "Epoch 31/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0155 - val_loss: 0.0155\n",
      "Epoch 32/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0154 - val_loss: 0.0154\n",
      "Epoch 33/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 34/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0152 - val_loss: 0.0152\n",
      "Epoch 35/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 36/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 37/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 38/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 39/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 40/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 41/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 42/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 43/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 44/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 45/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 46/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 47/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 48/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 49/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 50/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 51/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 52/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 53/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 54/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 55/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0136 - val_loss: 0.0135\n",
      "Epoch 56/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 57/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 58/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 59/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 60/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 61/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 62/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 63/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 64/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 65/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 66/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 67/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 68/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 69/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 70/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 71/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 72/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 73/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 74/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 75/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 76/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 77/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 78/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 79/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 80/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 81/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 82/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 83/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 84/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 85/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 86/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 87/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 88/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 89/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 90/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 91/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 92/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 93/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 94/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 95/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 96/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 97/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 98/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 99/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 100/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 101/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 102/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 103/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 104/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 105/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 106/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 107/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 108/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 109/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 110/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 111/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 112/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 113/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 114/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 115/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 116/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 117/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 118/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 119/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 120/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 121/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 122/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 123/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 124/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 125/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 126/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 127/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 128/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 129/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 130/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 131/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 132/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 133/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 134/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 135/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 136/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 137/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 138/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 139/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 140/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 141/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 142/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 143/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 144/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 145/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 146/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 147/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 148/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 149/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 150/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 151/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 152/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 153/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 154/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 155/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 156/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 157/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 158/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 159/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 160/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 161/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 162/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 163/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 164/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 165/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 166/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 167/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 168/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 169/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 170/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 171/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 172/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 173/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 174/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 175/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 176/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 177/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 178/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 179/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 180/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 181/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 182/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 183/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 184/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 185/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 186/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 187/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 188/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 189/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 190/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 191/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 192/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 193/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 194/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 195/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 196/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 197/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 198/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 199/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 200/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Restoring model weights from the end of the best epoch: 200.\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE AUTOENCODER\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    x_train, x_train,       # input = output bec autoencoder tries to reconstruct\n",
    "    epochs=200,              # number of times the model sees all data\n",
    "    batch_size=256,\n",
    "    validation_data=(x_val, x_val),  #check reconstruction on validation set (no attacks)\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    "    # shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4218901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51206/51206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 892us/step\n",
      "\u001b[1m12802/12802\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 889us/step\n"
     ]
    }
   ],
   "source": [
    "# reconstruction error = how much the autoencoder failed to recreate the input\n",
    "\n",
    "# get reconstructed outputs\n",
    "train_pred = autoencoder.predict(x_train)\n",
    "val_pred = autoencoder.predict(x_val)\n",
    "\n",
    "# compute reconstruction error\n",
    "train_mse = np.mean(np.square(x_train - train_pred), axis=1)\n",
    "val_mse = np.mean(np.square(x_val - val_pred), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0e07593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26074/26074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 931us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.00028305, 0.01156217, 0.00403759, 0.00050524, 0.05502232,\n",
       "        0.00724198, 0.00182937, 0.00140358, 0.03670128, 0.00114212]),\n",
       " array([0.00029553, 0.00104743, 0.00028933, 0.00024415, 0.00650014,\n",
       "        0.00029178, 0.0005615 , 0.01410239, 0.00028248, 0.00462177]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on traffic with anomalies\n",
    "# low error = normal behavior it understands\n",
    "# high error = unusual behavior = anomaly\n",
    "\n",
    "test_pred = autoencoder.predict(x_test)     # get reconstructed output of x+test\n",
    "\n",
    "test_mse = np.mean(np.square(x_test - test_pred), axis=1)\n",
    "\n",
    "train_mse[:10] , test_mse[:10]   #just to see examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7eb2ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.0184097715973606\n"
     ]
    }
   ],
   "source": [
    "# set anomaly threshold \n",
    "# and decide which reconstruction errors indicate anomalies\n",
    "# We want to decide which error value counts as an anomaly.\n",
    "\n",
    "\n",
    "best_threshold = np.percentile(val_mse, 88)  # top % of reconstruction error\n",
    "\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "# print(\"Best F1:\", best_f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e86b97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies detected: 424583\n",
      "Actual number of anomalies: 424704.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = (test_mse > best_threshold).astype(int)\n",
    "print(\"Number of anomalies detected:\", np.sum(y_pred))\n",
    "print(\"Actual number of anomalies:\", np.sum(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "81743cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8820191119522213\n",
      "Precision:  0.8842205175430953\n",
      "Recall:  0.8839685993068114\n",
      "F1-score;  0.8840945404792491\n",
      "Confusion matrix:\n",
      " [[360485  49158]\n",
      " [ 49279 375425]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)     #how many of the detected anomalies were actually attacks\n",
    "print(\"Recall: \", recall)           #how many actual attacks were caught\n",
    "print(\"F1-score; \", f1)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6bfe2820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHHCAYAAACr0swBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXs9JREFUeJzt3Qd4FFXXwPGTACn03qR3QpUiTZo0BQQElCa9CALSm9IRQYp0wfYCKiCggNKlo/TeBKQpIFV6C4Sw33Mu36y7YUkhWcgm/5/PmN2ZO2U3S3Jyzr13vGw2m00AAADgxNv5KQAAAAiSAAAAnoJMEgAAgAsESQAAAC4QJAEAALhAkAQAAOACQRIAAIALBEkAAAAuECQBAAC4QJAExHDHjh2TqlWrSpIkScTLy0sWLVoUpcf/66+/zHFnzJgRpcf1ZBUqVDALAM9GkAQ8BydOnJD33ntPsmXLJn5+fpI4cWIpU6aMTJgwQe7du+fWczdv3lwOHDggw4cPl++++06KFSsmMUWLFi1MgKbvp6v3UQNE3a7LmDFjInz8c+fOyeDBg2Xv3r1RdMUAPEncF30BQEy3dOlSefvtt8XX11eaNWsm+fPnlwcPHsjvv/8uvXr1kkOHDsmXX37plnNr4LBlyxb56KOPpFOnTm45R+bMmc154sWLJy9C3Lhx5e7du7J48WJ55513nLbNmjXLBKWBgYHPdGwNkoYMGSJZsmSRwoULh3u/X3/99ZnOByB6IUgC3OjUqVPSsGFDE0isXbtW0qVLZ9/WsWNHOX78uAmi3OXy5cvma9KkSd12Ds3SaCDyomjwqVm5OXPmPBEkzZ49W2rUqCE//fTTc7kWDdbix48vPj4+z+V8ANyLchvgRqNGjZLbt2/LN9984xQgWXLkyCFdunSxP3/48KEMGzZMsmfPbn75awbjww8/lPv37zvtp+tr1qxpslGvvPKKCVK0lPftt9/a22iZSIMzpRkrDWZ0P6tMZT12pPtoO0erVq2SV1991QRaCRMmlNy5c5trCqtPkgaFZcuWlQQJEph9a9euLYcPH3Z5Pg0W9Zq0nfadatmypQk4wqtx48ayfPlyuX79un3djh07TLlNt4V09epV6dmzpxQoUMC8Ji3XvfHGG7Jv3z57m/Xr10vx4sXNY70eq2xnvU7tc6RZwV27dkm5cuVMcGS9LyH7JGnJU79HIV9/tWrVJFmyZCZjBSD6IUgC3EhLQBq8lC5dOlzt27RpIwMHDpQiRYrIuHHjpHz58jJixAiTjQpJA4v69etLlSpVZOzYseaXrQYaWr5TdevWNcdQjRo1Mv2Rxo8fH6Hr12NpMKZB2tChQ815atWqJZs2bQp1v9WrV5sA4NKlSyYQ6t69u2zevNlkfDSoCkkzQLdu3TKvVR9rIKJlrvDS16oBzIIFC5yySHny5DHvZUgnT540Hdj1tX322WcmiNR+W/p+WwFL3rx5zWtW7dq1M++fLhoQWa5cuWKCKy3F6XtbsWJFl9enfc9SpUplgqXg4GCz7osvvjBluUmTJkn69OnD/VoBPEc2AG5x48YNm/4Tq127drja792717Rv06aN0/qePXua9WvXrrWvy5w5s1m3ceNG+7pLly7ZfH19bT169LCvO3XqlGk3evRop2M2b97cHCOkQYMGmfaWcePGmeeXL19+6nVb55g+fbp9XeHChW2pU6e2Xblyxb5u3759Nm9vb1uzZs2eOF+rVq2cjvnWW2/ZUqRI8dRzOr6OBAkSmMf169e3VapUyTwODg62pU2b1jZkyBCX70FgYKBpE/J16Ps3dOhQ+7odO3Y88dos5cuXN9umTZvmcpsujlauXGnaf/zxx7aTJ0/aEiZMaKtTp06YrxHAi0MmCXCTmzdvmq+JEiUKV/tly5aZr5p1cdSjRw/zNWTfpYCAAFPOsmimQkthmiWJKlZfpp9//lkePXoUrn3Onz9vRoNpVit58uT29QULFjRZL+t1Omrfvr3Tc31dmqWx3sPw0LKalsguXLhgSn361VWpTWkp09v78Y8/zezouaxS4u7du8N9Tj2OluLCQ6dh0BGOmp3SzJeW3zSbBCD6IkgC3ET7uSgtI4XH33//bX5xaz8lR2nTpjXBim53lClTpieOoSW3a9euSVRp0KCBKZFpGTBNmjSm7Ddv3rxQAybrOjXgCElLWP/++6/cuXMn1Neir0NF5LVUr17dBKRz5841o9q0P1HI99Ki16+lyJw5c5pAJ2XKlCbI3L9/v9y4cSPc53zppZci1ElbpyHQwFGDyIkTJ0rq1KnDvS+A548gCXBjkKR9TQ4ePBih/UJ2nH6aOHHiuFxvs9me+RxWfxmLv7+/bNy40fQxatq0qQkiNHDSjFDItpERmddi0WBHMzQzZ86UhQsXPjWLpD755BOTsdP+Rd9//72sXLnSdFDPly9fuDNm1vsTEXv27DH9tJT2gQIQvREkAW6kHYN1IkmdqygsOhJNf0HriCxHFy9eNKO2rJFqUUEzNY4jwSwhs1VKs1uVKlUyHZz/+OMPMymllrPWrVv31Nehjh49+sS2I0eOmKyNjnhzBw2MNBDR7J2rzu6WH3/80XSy1lGH2k5LYZUrV37iPQlvwBoemj3T0pyWSbUjuI581BF4AKIvgiTAjXr37m0CAi1XabATkgZQOvLJKhepkCPQNDhROt9PVNEpBrSspJkhx75EmoEJOVQ+JGtSxZDTElh0qgNtoxkdx6BDM2o6mst6ne6ggY9OoTB58mRTpgwtcxUySzV//nz5559/nNZZwZyrgDKi+vTpI6dPnzbvi35PdQoGHe32tPcRwIvHZJKAG2kwokPRtUSl/XEcZ9zWIfH6i1k7OKtChQqZX5o6+7b+Utbh6Nu3bze/VOvUqfPU4eXPQrMn+kv7rbfekg8++MDMSTR16lTJlSuXU8dl7WSs5TYN0DRDpKWizz//XDJkyGDmTnqa0aNHm6HxpUqVktatW5sZuXWou86BpFMCuItmvfr37x+uDJ++Ns3s6PQMWvrSfkw6XUPI75/2B5s2bZrp76RBU4kSJSRr1qwRui7NvOn7NmjQIPuUBNOnTzdzKQ0YMMBklQBEQy9wZB0Qa/z555+2tm3b2rJkyWLz8fGxJUqUyFamTBnbpEmTzHB0S1BQkBm2njVrVlu8ePFsGTNmtPXr18+pjdLh+zVq1Ahz6PnTpgBQv/76qy1//vzmenLnzm37/vvvn5gCYM2aNWYKg/Tp05t2+rVRo0bm9YQ8R8hh8qtXrzav0d/f35Y4cWLbm2++afvjjz+c2ljnCznFgB5L1+uxwzsFwNM8bQoAnSohXbp05vr0Ords2eJy6P7PP/9sCwgIsMWNG9fpdWq7fPnyuTyn43Fu3rxpvl9FihQx319H3bp1M9Mi6LkBRD9e+r8XHagBAABEN/RJAgAAcIEgCQAAwAWCJAAAAIIkAACA8CGTBAAA4AJBEgAAgAtMJhmN6C0pzp07Zyati8rbIQAAng+dVUdvi6P3bdTJTd0lMDDQTEobWXqDZj8/vyi5ppiIICka0QApY8aML/oyAACRdObMGTMzvbsCJP9EKUQe3o30sfT2PadOnSJQegqCpGhEM0jKp2hn8Yrr+6IvB3CL08sG8M4ixrp186bkyJrR/vPcHUwG6eFd8Q1oLhLH59kPFPxALvwx0xyPbJJrBEnRiFVi0wCJIAkxVeLEiV/0JQBu91y6TMT1E69IBEk2L7olh4UgCQAAT6RxWGSCMbq+hokgCQAAT6SZoMhkg8gkhYlcGwAAgAtkkgAA8ERaaotUuY16W1gIkgAA8ESU29yOchsAAIALZJIAAPBElNvcjiAJAACPFMnRbRSTwkS5DQAAwAUySQAAeCLKbW5HkAQAgCdidJvbUW4DAABwgUwSAACeiHKb2xEkAQDgiSi3uR1BEgAAnohMktvRJwkAAMAFMkkAAHgiym1uR5AEAIDHltu8I7c/QkW5DQAAwAUySQAAeCJvr8dLZPZHqAiSAADwRPRJcjvKbQAAAC4QJAEA4MnzJEVmiYCpU6dKwYIFJXHixGYpVaqULF++3L69QoUK4uXl5bS0b9/e6RinT5+WGjVqSPz48SV16tTSq1cvefjwoVOb9evXS5EiRcTX11dy5MghM2bMeOJapkyZIlmyZBE/Pz8pUaKEbN++3Wl7YGCgdOzYUVKkSCEJEyaUevXqycWLFyWiCJIAAPDkcltklgjIkCGDjBw5Unbt2iU7d+6U1157TWrXri2HDh2yt2nbtq2cP3/evowaNcq+LTg42ARIDx48kM2bN8vMmTNNADRw4EB7m1OnTpk2FStWlL1790rXrl2lTZs2snLlSnubuXPnSvfu3WXQoEGye/duKVSokFSrVk0uXbpkb9OtWzdZvHixzJ8/XzZs2CDnzp2TunXrRvwtttlstgjvBbe4efOmJEmSRHxL9BSvuL68y4iRrq3/+EVfAuDWn+NpUiSRGzdumGyLW39XlB8kXnH9nvk4toeBcn/DkEhda/LkyWX06NHSunVrk0kqXLiwjB8/3mVbzTrVrFnTBCxp0qQx66ZNmyZ9+vSRy5cvi4+Pj3m8dOlSOXjwoH2/hg0byvXr12XFihXmuWaOihcvLpMnTzbPHz16JBkzZpTOnTtL3759zetJlSqVzJ49W+rXr2/aHDlyRPLmzStbtmyRkiVLhvv1kUkCACAWl9s06HJc7t+/H+apg4OD5YcffpA7d+6Ysptl1qxZkjJlSsmfP7/069dP7t69a9+mAUqBAgXsAZLSDJCe08pGaZvKlSs7nUvb6HqlWSjNZDm28fb2Ns+tNro9KCjIqU2ePHkkU6ZM9jbhxeg2AABi8eg2zcI40jLW4MGDXe5y4MABExRpnx/t67Nw4UIJCAgw2xo3biyZM2eW9OnTy/79+01W6OjRo7JgwQKz/cKFC04BkrKe67bQ2mggde/ePbl27ZoJ0Fy10WyRdQzNSiVNmvSJNtZ5wosgCQCAWHyD2zNnzjiV27TD9NPkzp3b9BXSktaPP/4ozZs3N31+NFBq166dvZ1mjNKlSyeVKlWSEydOSPbs2cUTUW4DACAWs0arWUtoQZKPj48ZcVa0aFEZMWKE6TQ9YcIEl22175A6fvy4+Zo2bdonRphZz3VbaG30uvz9/U0pL06cOC7bOB5Dy3Laj+lpbcKLIAkAAE/0nEe3uaKdpp/Wh0kzTkozSkrLdFqucxyFtmrVKhMAWSU7bbNmzRqn42gbq9+TBmkaoDm20WvQ51Yb3R4vXjynNlr20+kHHPtPhQflNgAAYnG5Lbz69esnb7zxhukAfevWLTN6TOc00uH5WlLT59WrVzdzE2mfJB2GX65cOTO3kqpataoJhpo2bWqmBtD+Qf379zfzGVnZK51XSUet9e7dW1q1aiVr166VefPmmRFvFh3+r2W+YsWKySuvvGJG02kH8pYtW5rtOvJPR9tpOx19p0GYjnzTACkiI9sUQRIAAAjTpUuXpFmzZmb+Iw1ENPjRAKlKlSqmX9Pq1avtAYt2BtcJHDUIsmiZbMmSJdKhQwcTsCRIkMAEO0OHDrW3yZo1qwmINMDSMp7OzfT111+bEW6WBg0amCkDdH4lDbR02gGdHsCxM/e4cePMqDe9Bs106f6ff/55hL/LzJMUjTBPEmID5klCTPZc50mqPFK84kVinqSgQLm/uq9br9XTkUkCAMATPedyW2xEx20AAAAXyCQBAOCxmaTITCZJJiksBEkAAMTiGbfxdLxDAAAALpBJAgDAE9Fx2+0IkgAA8ESU29yOIAkAAE9EJsnt6JMEAADgApkkAAA8EeU2tyNIAgDAE1FuczvKbQAAAC6QSQIAwAN5eXmZJRIHiMrLiZEIkgAA8EAESe5HuQ0AAMAFMkkAAHgirZZFpmJGtS1MBEkAAHggym3uR7kNAADABTJJAAB4IDJJ7keQBACAByJIcj+CJAAAPBBBkvvRJwkAAMAFMkkAAHgipgBwO4IkAAA8EOU296PcBgAA4AKZJAAAPJDenzZyN7iNyquJmQiSAADwQF76X2SCJKKkMFFuAwAAcIFMEgAAHoiO2+5HkAQAgCdiCgC3o9wGAADgApkkAAA8kVfkOm7bItXpO3YgSAIAIBb2SYrcyLjYgSAJAAAPRJDkfvRJAgAAcIFMEgAAnojRbW5HkAQAgAei3OZ+lNsAAABcIJMEAIAHIpPkfgRJAAB4IIIk96PcBgAA4AKZJAAAPBCZJPcjSAIAwBMxBYDbUW4DAABwgUwSAAAeiHKb+5FJAgDAg4OkyCwRMXXqVClYsKAkTpzYLKVKlZLly5fbtwcGBkrHjh0lRYoUkjBhQqlXr55cvHjR6RinT5+WGjVqSPz48SV16tTSq1cvefjwoVOb9evXS5EiRcTX11dy5MghM2bMeOJapkyZIlmyZBE/Pz8pUaKEbN++3Wl7eK4lPAiSAADwQM87SMqQIYOMHDlSdu3aJTt37pTXXntNateuLYcOHTLbu3XrJosXL5b58+fLhg0b5Ny5c1K3bl37/sHBwSZAevDggWzevFlmzpxpAqCBAwfa25w6dcq0qVixouzdu1e6du0qbdq0kZUrV9rbzJ07V7p37y6DBg2S3bt3S6FChaRatWpy6dIle5uwriXc77HNZrNFeC+4xc2bNyVJkiTiW6KneMX15V1GjHRt/ccv+hIAt/4cT5Miidy4ccNkW9z5uyJ9m9ni7RP/mY/z6MFdOfd140hda/LkyWX06NFSv359SZUqlcyePds8VkeOHJG8efPKli1bpGTJkibrVLNmTROwpEmTxrSZNm2a9OnTRy5fviw+Pj7m8dKlS+XgwYP2czRs2FCuX78uK1asMM81c1S8eHGZPHny49fx6JFkzJhROnfuLH379jWvJ6xrCS8ySQAAePLotsgszyg4OFh++OEHuXPnjim7aXYpKChIKleubG+TJ08eyZQpkwlMlH4tUKCAPUBSmgHSoM/KRmkbx2NYbaxjaBZKz+XYxtvb2zy32oTnWsKLjtsAAMTijtsapDjSvkC6uHLgwAETFGmfH+3rs3DhQgkICDClMc0EJU2a1Km9BkQXLlwwj/WrY4Bkbbe2hdZGr/HevXty7do1E6C5aqPZIusYYV1LeJFJAgAgFtNSlZbvrGXEiBFPbZs7d24TEG3btk06dOggzZs3lz/++ENiKjJJbqQ99LXzmUa+ISNahK1VrVekVe1XJGPax+/dkb8uyeiZ62T19mP2NsUDMkr/NlWkaN4MEvzokRw8fkHq9ZohgQ8ej5ZImshfRn1QU6qVzi3a/e6XDX9Iv8lL5c69B0+cL+tLyWXDVx1NfTtLzeFO29rXL2WuJ0OapHL1xl35ecNBGfrVKrn//+fp0+I16dviNad9/jx9WUo0m8C3Gs9s3IxfZeiUX6R9wwoyosfjvhWnzl6WARMWyta9J+VB0EOpVCqvfNrzbUmd4r8+JWP+t0J+/f2QHPzzrMSLF1f+Xjf6iWMnK97piXVfD28h9aoWsz+ft3yHTPxutZw8fUkSJ/SXyqUDZOgHdSR50oR8V2NQJunMmTNOfZKelkVSmqHREWeqaNGismPHDpkwYYI0aNDAlMK075Dj7zsdUZY2bVrzWL+GHIVmjThzbBNyFJo+1+vz9/eXOHHimMVVG8djhHUtMS6T1KJFC/MN1Z71jhYtWhSpDwmir3OXb8iQL3+Viu2mymvvTZXfdp+UWcObSJ4sqe0B0o+jmsu6ncelcodpUqn9NPlq4VZ55DAW4av+b0uerKmlbs8Z0rDf91K6UGYZ36P2E+eKG8dbvh7wjmzd/9cT2+pXKiiD2lWVUTPXSYnmE6TzqIXyVsUCMqBNFad2h09dlNx1R9qXNzp/5Zb3BbHD7kN/y4yFmyRfzpfs6+7cuy91O00RL/GSn6d2luVfd5MHQcHSqPsXJri3BAUFS53KL0uremVDPceUge/KkeWf2Jca5QvZt23dd0I6DP5WmtYqJVvmfiTTR7aWXYf+li7D57jpFSOi9HMQqdFt/98pyRrSby2hBUkh6efu/v37JmCKFy+erFmzxr7t6NGjZsi/lueUftVyneMotFWrVplzasnOauN4DKuNdQwN0vRcjm30GvS51SY81xIjM0k6H8Knn34q7733niRLlixKjqnRpr7piH5WbDnq9Pzjb1abzFKxgIwmqzS8U3X5YsEWGT97o73N8TP/2h/nypRKKpfIJRXf+1z2Hj1n1vWZuFTmjWwqA6aukAtXbtnb9m9dWY6d/lc27D4hr+TP5HRefb7twGn5cc1+8/zMhevy05r95jocPQx+JJeu3o7idwGx0e2796XdwBky4cNGJitk2bbvpJw+f0U2fN/HZHbU54ObStbXesvGHX9KhRJ5zLp+79UwX2cv3hrqeZIk8pc0KV2Patqx/5RkSpdC3mtYwTzP/FJKaVm3jEz4dnWUvU54ln79+skbb7xhOkDfunXLjB7TiokOz9cyXevWrc3QfB3xpoGPjjbToMQaTVa1alUTDDVt2lRGjRpl+gf179/fzGdkBWbt27c3o9Z69+4trVq1krVr18q8efPMiDeLnkPLfMWKFZNXXnlFxo8fbzqQt2zZ0mwPz7XEuEyS0p7qmioLrV76008/Sb58+cwbrhNNjR071mm7rhs2bJg0a9bMvHHt2rUz8zRoSm7JkiWm3qqTXOmwwbt375p5HHQfDco++OAD02HM8t1335lvUqJEicx1NW7c2ClCRtTx9vaSuq8VkPh+PrLj0GlJmTSBySRdvnZHVk5uJ0cX9JUl41tLyQKZ7fsUz5dRrt+6Zw+Q1PpdJ0ymSctzlrIvZ5PaFfJLr/GLXZ57+8HTUjh3eimS5/Ff9JnTJZMqJXPJqq1/OrXL9lIK+ePH3rJndnf58qO3JUPqJHwE8Ex6jZorVcvktwc9Fi3vagbA1+e/v2/9fOKafx+a+Yn4eeZJ9sp9pFLz0fL9L1tMSdpSvGBW+efiNfl10yGz/tKVm/Lzmr1SpfTjv/gR++ZJunTpkvndqb8nK1WqZEptGiBVqfI4qz5u3DgzxF8nbixXrpz5vbhgwQL7/lom09+z+lUDlnfffdccb+jQofY2WbNmNQGRZo90/iP9Hf7111+bEW4WLe2NGTPGzK9UuHBh00dKpwdw7Mwd1rXEyEySvrGffPKJCUY0YNGJrRzpsL933nlHBg8ebN5Enazq/fffNzNuarnOYr25OhGV+u2330xANHHiRDOkUSNknXTqrbfeMsHTsmXL5OTJk+bNLlOmjDm20iGGGnDpB0Y/PBq16nm0PaJGQNY0svLzduYXgfYjajpgthz9+7IUC3j8vdd+QJoVOnD8vDSsVlgWjW0ppVtOkpP/XJE0yRPJ5WvOmZ3g4Edy7eY9s00lS+wvn/etK+8N/1Fu3b3v8ho0g5Q8SXxZPqmt+aESL24c+d/P2+SzWRv+++z9cUY6jvzJZLLSpEgkfZq/JssmtpXSLSfKbRf9n4Cn+enXnbLvyBlZO7P3E9uKF8hi/lAYPOlnGdCxlglehkz+2XyuL/zrPEIpLB++V0PKFs9ljrd26xHp+elcuXP3vj1zVLJQdvlyWHNp/eH/JPB+kMmUvl42v4zu8/jnH2LfDW6/+eabMKs9OhO2Lk+TOXPmMH9HVqhQQfbs2RNqm06dOpklMtcS44IkpYGLRo4a4IT8hn322Wcmuh0wYIB5nitXLtPrXie6cgySdJbQHj162J9rkKQBj065nj17drNOM0maKdKOXjrMUVOE2gl73bp19iBJU4GWbNmymSBLJ7i6ffu22ScsWsfVxRJyGCZEjp35V8q1mSKJE/hJ7fL55PN+9aRml6/F+///ApqxeIfMXrHbPNZAqXyR7PJu9SKmU3V4TOhZxwRBm130RbKUKZxVur9bXnqOXyy7/jhrOniP7FxDeja9JWO+W2/aOHYmP3Tyouw8fFYO/NBT6lQsIN8v28W3EuFy9sI16Tf2J1kwuZP4+cZ7YnvKZIlkxsjW0mPkXPli7gaTQapXtagUypPRPI6IXm3esD8umDuj3L1333TStoKkIyfPS7+xP5p2r5XMKxf/vSEDJy6S7iN+kEkDmvAdRazgcUGS0n5JGuj07NnTaf3hw4fNFOmONPOj9Uotk2kmSmmJLCQtsVkBktK0nZbZHIMdXedYTtPMlWat9u3bZ0awWR0ntXOY1QktNFo2HDJkSIRee2wT9DBYTv1z1Tze9+c5eTlPBmlfr7SM+/9+SEf/di5vapYpQ+rHoxkuXr0lqZI5B6tx4nib7JFuU+WKZJM3yuSRTg3KmOfakVHbXF4zRLqO+VlmLd8tH7WqJPN+3SvfLX0c7Pxx6qIk8PeRcT1qy9jvNziVKCw3bwfK8bP/SraXkrvlfUHMtO/Iabl89ZZUaPqpfZ1miTbvOSFfzd8oFzeNNwHLnkWD5cr122bAQZJE8SV3tX6SpWrRSJ27aP4sMvqbFXL/QZD4+sQzI+tKFMouHzR9PCFf/pwvSXx/X6nedpx81KGmpE1JOflF4wa37ueRQZLWF7U+qZ3IHDNE4ZUgQYIn1mlPeEemrOJinRUIaScxvQZdZs2aZaZA1+BIn2tn8PDQ69cSnWMmSeerwNNpBsnHJ46cvnBNzl2+KTkypnTaniNjClm97XFWZ8ehM2YKgEK50psAS5V7OZs5xq7DZ83zqu9/KXHi/PcXePUyeeWDRmXl9U5fmuMrf9948uiRcyAUHPz4uSa0XN3YR4OorOmTy9xf9/LtRLiVK55bNs350Gldp6HfS84saaRLsyomgLek+P9h+Bt3HDVl5TfKFojUO33gz7OSNHF8EyCpe4EPJO7//2FpifP/2SruZhU9ECS5n0cGSUqnAtCym/YHsuh9WTZt2uTUTp9r2c3KIkUVndnzypUr5jqswEZv+BcRoc1qCpGBbauYgOfMpeuSyN9X6lcuKK8WziL1es00b8+kub9JvxaV5OCJC6bU1qjay5IzUyppPugH+zxFq7f9aUpq3T/72fQlGtWlpixYe8A+sk3bOCqc+yXzC+DwqUtOo+zef7u07D9+Xnb+cdZkhz5sXUlWbD5qD56GdnhdVmw+ImcuXpd0KRJJ35aVJPiRzYyCA8IrUQI/CciR3mldfH8fSZ4kgX39rF+2SK6saSVlsoSyff8p6ffZj/J+o4omkLKcuXBVrt+4a8p3+ofdgaOP/yjImjGVJIzvK8s3HjAZq2L5s5iy3rptR2Tc9F+l07uV7Md4vWwB6TJ8tnzz429SqWReuXDlhnw49icpmi+zpEvFvG/Rgf6RFpkZcJg9JwYHSXr/lyZNmph+QBbtZ6R9grQztfYb0nu06FDCzz//PMrPr0MgdeqASZMmmSGLejM+PS+iTsqkCWXqh/VMJ+ubdwJNXx8NkHSEmpr24xbx84knn3SsbjJGh05cMPMh/XXucXlOtf14vozuUlMWfdZKbI9s8svGQ9J30n9DScND+x1p4PRR68qSLmViuXL9jgmIhn3z31Dol1IlNvMsJU8cX/69cUe2Hfhbqrz/hVy5cTcK3xFA5Njfl8wEk9du3pVM6ZNLj5bV5P3GzhOZjpi2VOYs3WZ/Xu7dx/PLLZ72gbxaNJf5g+Hr+Rvlo3E/mc921gyp5ONudaV5ndL2fRq/WVJu3w2Ur+dtkAHjF5jpAsoWyy2DOz85zxgQU3nZPCRvqmU1nT1TJ4+0/PXXXyaTpOUt62XoFAA6cu3YsWOSLl06MzeCY98l7WfUtWtXs1h0CgB9rse3aF8jPZcOLXzaNcyZM0c+/PBDOX/+vBQpUsSUz2rVqmV65WuWK6Izblt3dvYt0VO84pJhQsx0bf3HL/oSALfRn+NpUiQxd6J3nMU6qs+hvyuydf5RvH2f7D4SXo/u35GTk+q79Vo9nccESbEBQRJiA4IkxGTPNUj64EeJE4kgKViDpIkESTFmMkkAAIDnxWP7JAEAEJsxus39CJIAAPBAjG5zP8ptAAAALpBJAgDAA+mtaCJ6OxpHtkjsG1sQJAEA4IEot7kf5TYAAAAXyCQBAOCBGN3mfgRJAAB4IMpt7keQBACAByKT5H70SQIAAHCBTBIAAB6ITJL7ESQBAOCB6JPkfpTbAAAAXCCTBACAB/LS/zSdFIn9ETqCJAAAPBDlNvej3AYAAOACmSQAADwQo9vcjyAJAAAPRLnN/Si3AQAAuEAmCQAAD0S5zf0IkgAA8ECU29yPIAkAAA9EJsn96JMEAADgApkkAAA8kdfjkltk9kfoCJIAAPBAlNvcj3IbAACAC2SSAADwQIxucz+CJAAAPBDlNvej3AYAAOACmSQAADwQ5Tb3I0gCAMADUW5zP8ptAAAALpBJAgDAA5FJcj+CJAAAPBB9ktyPIAkAAA9EJsn96JMEAADgApkkAAA8EOU29yNIAgDAA1Fucz/KbQAAIEwjRoyQ4sWLS6JEiSR16tRSp04dOXr0qFObChUq2IM3a2nfvr1Tm9OnT0uNGjUkfvz45ji9evWShw8fOrVZv369FClSRHx9fSVHjhwyY8aMJ65nypQpkiVLFvHz85MSJUrI9u3bnbYHBgZKx44dJUWKFJIwYUKpV6+eXLx4MULfaYIkAAA8kJdDye2Zlgieb8OGDSbo2Lp1q6xatUqCgoKkatWqcufOHad2bdu2lfPnz9uXUaNG2bcFBwebAOnBgweyefNmmTlzpgmABg4caG9z6tQp06ZixYqyd+9e6dq1q7Rp00ZWrlxpbzN37lzp3r27DBo0SHbv3i2FChWSatWqyaVLl+xtunXrJosXL5b58+ebaz937pzUrVs3Yu+xzWazRfB9gpvcvHlTkiRJIr4leopXXF/eZ8RI19Z//KIvAXDrz/E0KZLIjRs3JHHixG79XVFh1GqJ65/gmY/z8N4dWd+78jNf6+XLl00mSAOQcuXK2TNJhQsXlvHjx7vcZ/ny5VKzZk0TsKRJk8asmzZtmvTp08ccz8fHxzxeunSpHDx40L5fw4YN5fr167JixQrzXDNHmtWaPHmyef7o0SPJmDGjdO7cWfr27WteU6pUqWT27NlSv3590+bIkSOSN29e2bJli5QsWTJcr5FMEgAAsZgGXY7L/fv3w7XfjRs3zNfkyZM7rZ81a5akTJlS8ufPL/369ZO7d+/at2mAUqBAAXuApDQDpOc9dOiQvU3lypWdjqltdL3SLNSuXbuc2nh7e5vnVhvdrpkuxzZ58uSRTJky2duEBx23AQCIxaPbNAPjSEtYgwcPDnVfzdxoGaxMmTImGLI0btxYMmfOLOnTp5f9+/ebrJD2W1qwYIHZfuHCBacASVnPdVtobTSQunfvnly7ds2U7Vy10WyRdQzNSiVNmvSJNtZ5woMgCQCAWDy67cyZM07lNu0sHZaOHTuactjvv//utL5du3b2x5oxSpcunVSqVElOnDgh2bNnF09DuQ0AAA/k7RX5RWmA5LiEFSR16tRJlixZIuvWrZMMGTKE2lb7Dqnjx4+br2nTpn1ihJn1XLeF1kavzd/f35Ty4sSJ47KN4zG0LKf9mJ7WJjwIkgAAQJhsNpsJkBYuXChr166VrFmzhrmPjk5TmlFSpUqVkgMHDjiNQtORchoABQQE2NusWbPG6TjaRtcrLaMVLVrUqY2W//S51Ua3x4sXz6mNlv10+gGrTXhQbgMAwBOZPkmR6ZQUseYdO3Y0o8V+/vlnM1eS1bdHR9pphkdLarq9evXqZm4i7ZOkw/B15FvBggVNW50yQIOhpk2bmqkB9Bj9+/c3x7YyWDqvko5a6927t7Rq1coEZPPmzTMj3iw6/L958+ZSrFgxeeWVV8xoOp2KoGXLlvZrat26tWmnHcs1CNORbxoghXdkmyJIAgDAAz3v25JMnTrVPszf0fTp06VFixYmw7N69Wp7wKIdwnUCRw2CLFom01Jdhw4dTMCSIEECE+wMHTrU3kYzVBoQaYA1YcIEU9L7+uuvzQg3S4MGDcyUATq/kgZaOu2ATg/g2Jl73LhxZtSbXoOO2NP9P//884i9R8yTFH0wTxJiA+ZJQkz2POdJqjJujcTzT/jMxwm6d1tWdavk1mv1dGSSAADwQF7//19k9kfoCJIAAPBAjiPUnnV/hI7RbQAAAC6QSQIAIBZPJolIBkm//PKLhFetWrXC3RYAAHjG6LbYKFxBUp06dcIdler9VAAAAGJFkKQzWQIAgOjD28vLLJHZH27skxQYGCh+fn6ROQQAAHgGlNui4eg2LacNGzZMXnrpJUmYMKGcPHnSrB8wYIB888037rhGAADwlI7bkVkQxUHS8OHDZcaMGeaeKzoFuSV//vxm2nAAAIBYGSR9++238uWXX0qTJk3MPVgshQoVkiNHjkT19QEAgFDKbZFZEMV9kv755x/JkSOHy87dQUFBET0cAAB4BnTcjoaZpICAAPntt9+eWP/jjz/Kyy+/HFXXBQAA4FmZpIEDB0rz5s1NRkmzRwsWLJCjR4+aMtySJUvcc5UAAMCJVssiUzGj2uaGTFLt2rVl8eLFsnr1akmQIIEJmg4fPmzWValSJaKHAwAAz4DRbdF0nqSyZcvKqlWrov5qAAAAPH0yyZ07d5oMktVPqWjRolF5XQAAIBTeXo+XZxWZfWOLCAdJZ8+elUaNGsmmTZskadKkZt3169eldOnS8sMPP0iGDBnccZ0AAMBBZCeEZDJJN/RJatOmjRnqr1mkq1evmkUfaydu3QYAABArM0kbNmyQzZs3S+7cue3r9PGkSZNMXyUAAPB8MCFkNAuSMmbM6HLSSL2nW/r06aPqugAAQCgot0XDctvo0aOlc+fOpuO2RR936dJFxowZE9XXBwAAQum4HZkFUZBJSpYsmVMHrzt37kiJEiUkbtzHuz98+NA8btWqldSpUyc8hwQAAPD8IGn8+PHuvxIAABBulNuiSZCktyEBAADRB7clicaTSarAwEB58OCB07rEiRNH9poAAAA8L0jS/kh9+vSRefPmyZUrV1yOcgMAAO7l7eVllsjsjyge3da7d29Zu3atTJ06VXx9feXrr7+WIUOGmOH/3377bUQPBwAAnoHGOJFdEMWZpMWLF5tgqEKFCtKyZUszgWSOHDkkc+bMMmvWLGnSpElEDwkAAOD5mSS9DUm2bNns/Y/0uXr11Vdl48aNUX+FAADgqaPbIrMgioMkDZBOnTplHufJk8f0TbIyTNYNbwEAgHtRbouGQZKW2Pbt22ce9+3bV6ZMmSJ+fn7SrVs36dWrlzuuEQAAIPr3SdJgyFK5cmU5cuSI7Nq1y/RLKliwYFRfHwAAcIHRbdF8niSlHbZ1AQAAz09kR6jRJSmKgqSJEydKeH3wwQfhbgsAAJ4NtyWJJkHSuHHjwv0NI0gCAACxJkiyRrPh+Ti9bAC3d0GMlax4pxd9CYDb2IKdb9Xl7pFX3pHcH27ukwQAAJ4/ym3uRyAJAADgApkkAAA8kI5O82Z0m1sRJAEA4IG8IxkkRWbf2IJyGwAAQFQFSb/99pu8++67UqpUKfnnn3/Muu+++05+//33ZzkcAACIIG5wGw2DpJ9++kmqVasm/v7+smfPHrl//75Zf+PGDfnkk0/ccY0AAOAp5bbILIjiIOnjjz+WadOmyVdffSXx4sWzry9Tpozs3r07oocDAACIGR23jx49KuXKlXtifZIkSeT69etRdV0AACAU3LstGmaS0qZNK8ePH39ivfZHypYtW1RdFwAACIW3l1ekl4gYMWKEFC9eXBIlSiSpU6eWOnXqmMSJo8DAQOnYsaOkSJFCEiZMKPXq1ZOLFy86tTl9+rTUqFFD4sePb47Tq1cvefjwoVOb9evXS5EiRcTX11dy5MghM2bMeOJ6pkyZIlmyZBE/Pz8pUaKEbN++PcLXEuVBUtu2baVLly6ybds202ns3LlzMmvWLOnZs6d06NAhoocDAACRuC1JZJaI2LBhgwk6tm7dKqtWrZKgoCCpWrWq3Llzx96mW7dusnjxYpk/f75przFC3bp17duDg4NNgPTgwQPZvHmzzJw50wRAAwcOdLoVmrapWLGi7N27V7p27Spt2rSRlStX2tvMnTtXunfvLoMGDTJdfQoVKmT6S1+6dCnc1xIeXjabzRaRHbS5dtDWiPLu3btmnUZ6GiQNGzYsQieHs5s3b5qy5cUrN7h3G2Is7t2GmH7vtvsHvjKDmRInTuzW3xXd5+8S3/gJn/k49+/els/eLvrM13r58mWTCdIARLvh6HFSpUols2fPlvr165s2R44ckbx588qWLVukZMmSsnz5cqlZs6YJWNKkSWPaaD/nPn36mOP5+PiYx0uXLpWDBw/az9WwYUPTpWfFihXmuWaONKs1efJk8/zRo0eSMWNG6dy5s/Tt2zdc1+KWTJJmjz766CO5evWqeQEaUeoLI0ACAOD590mKzGIFXY6LNWo9LBqIqOTJk5uvu3btMtmlypUr29vkyZNHMmXKZAITpV8LFChgD5CUZoD0vIcOHbK3cTyG1cY6hmah9FyObby9vc1zq014rsWtk0lqtBcQECCvvPKKqfUBAIDnx1si2SdJHkdJmoHRzJS1aKUoLI8ePTJlMB3Znj9/frPuwoULJjZImjSpU1sNiHSb1cYxQLK2W9tCa6OB1L179+Tff/81ZTtXbRyPEda1uGV0m9YINZv0NGvXro3oIQEAwAty5swZp3KbdqEJS8eOHU01KaZPIh3hIKlw4cJOzzWdpR2r9M1q3rx5VF4bAABw8xQAGiBFpE9Sp06dZMmSJbJx40bJkCGD0+h3LYVp3yHHDI6OKNNtVpuQo9CsEWeObUKOQtPneo06kXWcOHHM4qqN4zHCuha3BEnjxo1zuX7w4MFy+/btiB4OAAB4wA1ubTab6Ri9cOFCM0Q/a9asTtuLFi1qJples2aNGW6vdIoAHfKvtzFT+nX48OFmFJp2+lY6Uk4DIO3CY7VZtmyZ07G1jXUMLaPpufQ8Og2BVf7T5xrAhfda3BIkPY3ey037J40ZMyaqDgkAAKKJjh07mtFiP//8s5kryerbo/2YNMOjX1u3bm2G5mtnbg18NKjSoMQaTaZTBmgw1LRpUxk1apQ5Rv/+/c2xrTJf+/btzai13r17S6tWrUw3nnnz5pkRbxY9h1avihUrZmKP8ePHm6kIWrZsab+msK7luQZJ2ltcJ3QCAADup+WyiE4IGXL/iJg6dar5WqFCBaf106dPlxYtWtirTTrSTLM3OkpOR6V9/vnn9rZaJtNSnc6rqAFLggQJTLAzdOhQexvNUGlApPMcTZgwwZT0vv76a3MsS4MGDczIep1fSQMt7Qqk0wM4duYO61rcMk9SyImYdPfz58/Lzp07ZcCAAWZiJzwb5klCbMA8SYjJnuc8SR8u2i1+CRI983EC79yST+oUceu1eroIZ5L0G+NIo7TcuXObKFDTaAAAALEuSNJ5CbTepxNBJUuWzH1XBQAAolXH7dgoQpNJai1Rs0U6pA4AALw4XlHwH6J4xm2dWfPkyZMR3Q0AALghkxSZBVEcJH388cfmZrbaO107bIe85wsAAECs6pOkHbN79Ogh1atXN89r1arldHsSHeWmz7XfEgAAcC/6JEWjIGnIkCFmgqd169a594oAAECYNDER2r1Uw7M/oihIsqZTKl++fHh3AQAAiB1TABB1AgAQPVBui2ZBUq5cucIMlK5evRrZawIAAGHQX8eRqZhRbYviIEn7JYWccRsAAEBie5DUsGFDSZ06tfuuBgAAhIve3DYyN7iNzL6xRbiDJPojAQAQfdAnKRpNJmmNbgMAAIgNwp1JevTokXuvBAAAhF8kO25z67Yo7pMEAACiB2/xMktk9kfoCJIAAPBATAEQDW9wCwAAEBuQSQIAwAMxus39CJIAAPBAzJPkfpTbAAAAXCCTBACAB6LjtvsRJAEA4KlTAETmtiRMARAmym0AAAAukEkCAMADUW5zP4IkAAA8tBQUmXIQpaSw8R4BAAC4QCYJAAAP5OXlZZbI7I/QESQBAOCBNMSJTJhDiBQ2giQAADwQM267H32SAAAAXCCTBACAh6Jk5l4ESQAAeCDmSXI/ym0AAAAukEkCAMADMQWA+xEkAQDggZhx2/0otwEAALhAJgkAAA9Euc39CJIAAPBAzLjtfpTbAAAAXCCTBACAB6Lc5n4ESQAAeCBGt7kfQRIAAB6ITJL70ScJAADABTJJAAB4IEa3uR+ZJAAAPPgGt5FZImLjxo3y5ptvSvr06U2pb9GiRU7bW7RoYS8BWsvrr7/u1Obq1avSpEkTSZw4sSRNmlRat24tt2/fdmqzf/9+KVu2rPj5+UnGjBll1KhRT1zL/PnzJU+ePKZNgQIFZNmyZU7bbTabDBw4UNKlSyf+/v5SuXJlOXbsWMReMEESAAAIjzt37kihQoVkypQpT22jQdH58+fty5w5c5y2a4B06NAhWbVqlSxZssQEXu3atbNvv3nzplStWlUyZ84su3btktGjR8vgwYPlyy+/tLfZvHmzNGrUyARYe/bskTp16pjl4MGD9jYaWE2cOFGmTZsm27ZtkwQJEki1atUkMDAwQt9sL5uGW4gW9MORJEkSuXjlhomygZgoWfFOL/oSALexBT+Q+we+khs33Pdz3Ppd8cPmYxI/YaJnPs7d27ekYemcz3StXl5esnDhQhOcOGaSrl+//kSGyXL48GEJCAiQHTt2SLFixcy6FStWSPXq1eXs2bMmQzV16lT56KOP5MKFC+Lj42Pa9O3b1xzzyJEj5nmDBg1MwKZBlqVkyZJSuHBhExRpWKPH6tGjh/Ts2dNs19eYJk0amTFjhjRs2DDcr5NyGwAAsbjcpkGX43L//v1nvqb169dL6tSpJXfu3NKhQwe5cuWKfduWLVtMic0KkJSWwby9vU22x2pTrlw5e4CkNAN09OhRuXbtmr2N7udI2+h6derUKRNkObbRoLJEiRL2NuFFkAQAQCym/X40iLCWESNGPNNxXn/9dfn2229lzZo18umnn8qGDRvkjTfekODgYLNdAxcNoBzFjRtXkidPbrZZbTTj48h6HlYbx+2O+7lqE16MbgMAwAN5/f9/kdlfnTlzxqnc5uvr+0zHa+hQxtLO1AULFpTs2bOb7FKlSpXEE5FJAgAgFpfbNEByXJ41SAopW7ZskjJlSjl+/Lh5njZtWrl06ZJTm4cPH5oRb7rNanPx4kWnNtbzsNo4bnfcz1Wb8CJIAgAAUe7s2bOmT5IOw1elSpUyHbt11Jpl7dq18ujRI9NfyGqjI96CgoLsbXQknPZxSpYsmb2NlvQcaRtdr7JmzWqCIcc22tdK+z1ZbcKLIAkAAA+k5TLvSCwRLdXdvn1b9u7daxarg7Q+Pn36tNnWq1cv2bp1q/z1118mQKldu7bkyJHDdKpWefPmNf2W2rZtK9u3b5dNmzZJp06dTJlOR6Opxo0bm07bOrxfpwqYO3euTJgwQbp3726/ji5duphRcWPHjjUj3nSKgJ07d5pjmffFy0u6du0qH3/8sfzyyy9y4MABadasmTmH42i88KBPEgAAHuhZJoQMuX9E7Ny5UypWrGh/bgUuzZs3N0P3dRLImTNnmmyRBiQ639GwYcOcynezZs0ywYz2UdJRbfXq1TPzGVm04/ivv/4qHTt2lKJFi5pynU4K6TiXUunSpWX27NnSv39/+fDDDyVnzpxmioD8+fPb2/Tu3dtME6D76fW8+uqrJrDSyScj9B4xT1L0wTxJiA2YJwkx2fOcJ2nB9hOSIBLzJN25fUvqvpLdrdfq6Si3AQAAuEC5DQCAWDwFAJ6OIAkAAA/k7fV4icz+CB3lNgAAABfIJAEA4IEot7kfQRIAAB7oeU8BEBtRbgMAAHCBTBIAAB5IE0GRG92GsBAkAQDggRjd5n6U2wAAAFwgkxQJWbJkMTfR0wXP37gZv8rQKb9I+4YVZESP+mbdqbOXZcCEhbJ170l5EPRQKpXKK5/2fFtSp3g85f7pc1dk9DcrZOPOP+XSlZuSNmUSeeeN4tKjVTXxiff4n8PIL5fKp18tf+J88f185J/fPjOPgx4Gy7jpv8qcpdvk/OXrkiNzGhncqbZULh3wXN8DeLZW9V6VVvXKSsZ0yc3zIycvyOhvlsvqzX+Ydft/GepyvxZ9v5Gf1+wxj6/tmPzE9tYfTpcFq/6707qlRMFssuSLLnL45Hkp12SkfX23FlWlZsVCkjNzGgm8HyTb95+UwZN/luN/X7K3WTyti7xaNKfT8ab/9Lt0H/lDJN4BRAaj22JJkLRlyxZz8zm9O/DSpUtf9OXAA+w+9LfMWLhJ8uV8yb7uzr37UrfTFMmf8yX5eWpns+6TaUulUfcvZNX0HuZmin/+dVEePXok4/o1lGwZUskfJ85J10/myN1792VY17pmn07vVpaWdcs6na/O+xPl5YDM9ucfT10s85fvkPEfNZZcmdPImq2HpWnvr2TlN92lYO6Mz+19gGc7d+m6DJn8s5w4c9ncubxRjRIya0w7Kf/uSPNZzf16P6f2zd8qI53frSyrNx9yWv/+kO9kzZY/7M9v3Lr3xLkSJ/SXqUOayoYdf0rqFM73+ypdJId8PX+j7Pnjb4kbJ44MeP9NWTCpk5R852O5G/jA3k7/zY34Yon9+b3AoCh5H/BsGN0WS4Kkb775Rjp37my+njt3ztw9GHia23fvS7uBM2TCh41kzP9W2Ndv23dSTp+/Ihu+72N+IajPBzeVrK/1lo07/pQKJfKYTI9jtidLhpRy/PQl+d+Pv9mDpITxfc1iOfDnWTly6oKM7dfQvm7esu3SvWU1qVomn3neun5Z2bD9iEz+fq18Oaw53zyEy4rfDjo91+Bbs0vF8mc1WaVLV245ba9ZoZAsWr1b7tz7L3CxgqKQbUPSPwx+XLlTgoNtUqNCQadtb3/wudPz94d8L8dXjZTCeTPK5j0n7OvvBT4I8zx43h23I7c/onmfpNu3b8vcuXOlQ4cOUqNGDZkxY4Z92/r1681fV2vWrJFixYpJ/PjxpXTp0nL06FGnY0ydOlWyZ88uPj4+kjt3bvnuu++ctusxvvjiC6lZs6Y5Rt68eU326vjx41KhQgVJkCCBOe6JE//9MNDHtWvXljRp0kjChAmlePHisnr16qe+jlatWpnjOwoKCpLUqVOb4A9Rp9eouVK1TH4T9Di6/+Ch+V77+vwX+/v5xBVvby/Zuu+/721IN2/fk2RJ4j91+3c/b5YcmVJL6Zdz/HeuoIfi5xvPqZ2fr0+o5wFCo5/TulWKSnx/H9lx4NQT2wvlyWiylN//suWJbaN7v2OCmtUzekqTN0s+sb3xmyUl80spXJaRXUmc0M98vXbzrtP6t18vZs6z+YcPZWDHWuIf4t8AENO88CBp3rx5kidPHhPcvPvuu/K///1PbDabU5uPPvpIxo4dKzt37pS4ceOagMSycOFC6dKli/To0UMOHjwo7733nrRs2VLWrVvndIxhw4ZJs2bNZO/eveZ8jRs3Nm379etnjqvn7NSpk1PwVr16dROg7dmzx5QC33zzTTl9+rTL19GmTRtZsWKFnD9/3r5uyZIlcvfuXWnQoIHLfe7fvy83b950WhC6n37dKfuOnDE/oEMqXiCL6Tc0eNLPpkSg5TftnxQc/Egu/Ov6vT155rJ8OXeDtHjrVZfbtX/G/BU75d3apZzWv1Yyr3w+a62cOH3JlO/WbTssS9btlYtPOQ/wNAHZ08uZDWPl4qbx8lm/BtK011dy9NSFJ9o1rV1Kjpw8L9v3OwdQw6ctkVb9/idvdZwsi9fulTF9Gki7BuXt27NlTCWDOtaS9wZ+a/4thEX/0BjRvb5s3XtCDp/47+eZZqH0GLXaTzT9AbUv3xdkTV8ob/ESb69ILOSSon+QpFkWDY6UBiI3btyQDRs2OLUZPny4lC9fXgICAqRv376yefNmCQwMNNvGjBkjLVq0kPfff19y5col3bt3l7p165r1jjRweuedd0ybPn36yF9//SVNmjSRatWqmcySBlqaubIUKlTIBFH58+eXnDlzmiBLs1W//PKLy9ehmaiQWazp06fL22+/bTJRrowYMUKSJEliXzJmpC9LaM5euCb9xv4kXw5r8UQWR6VMlkhmjGxtShgZyvWQzBV7mTKE/gWuf6W76g9S/4MpUqfyy6avhytL1u+T23cCTV8RRyN71JdsmVLLK28Pk9Slu0rvUfPNX+uuzgOE5tjfF6VckxFSueUY+d9Pv5sSce6saZ3a6Oe9frViLrNIY75ZIdv2nzRl4QnfrpaJ362WD5pWNtv08/jVxy1k5JfLTEAfHmN6vyN5s6eT1h9Nd1o/c+EmWbv1sOnHp384dBj8nbxZsbBkeSkl3+AXXG6LzIJoHCRp2Wz79u3SqFEj81yzRJp1CVmeKljwv/p5unTpzNdLlx7/gz98+LCUKeP8C06f6/qnHUNLaKpAgQJO6zTwsrI5mknq2bOnCaCSJk1qAh095tMySVY2SQMjdfHiRVm+fLlT1iskzWJpUGgtZ86cCeXdwr4jp+Xy1VtSoemnkrLkB2bZtPu4fDF3g3msfyVrhmfPosFy7NcRcmLVSPliaHM5f+n6Ez/IdURarQ4T5JWC2WT8h48/f658t2izVCub3z46zjEg0w62/2z8zIxA2v7jAEkQ31eypE/BNwoRoiMlT53912RIdbTmwWP/mBGbjmq/Vlj8/Xzkh6XbwzzeroN/yUtpkpnRmgnj+0mRgMwyqtfbcnnLBLP0bvO6FMiVwTwuWyyX077aTj/vb3aYaP6ICOs8VqYKiKleaMdtDYYePnzo1FFby16+vr4yefJ/w1rjxYvnlApWWuKICFfHCO24GiCtWrXKZKRy5Mgh/v7+Ur9+fXnwwLnDpCMt52mmS/s7abYra9asUras8ygpR/o6dUH4lCueWzbN+dBpXaeh30vOLGmkS7MqEifOfzF/iqSPs3cbdxyVy9duyxtl/wuI9Ye/BkiF8mSSKQPfNaPeXPn7n3/lt13HZPbYdk+9Jv0LP33qpOYXnZY66lQuwrcTkaJlEB+HfnXq3dqlZfnGA3Ll+u0w99cA6NqNO2YKDP1clm443Gm7DjLQ4EinEfj7nytOAVKNCoXkzfYTzFQZ4TmPuvjvjQi8OkQpem7H3CBJg6Nvv/3W9DWqWrWq07Y6derInDlzTN+hsGimZ9OmTdK8+X8jivS5luYiQ4+hZby33nrLnlnSEl1oUqRIYa5ds0kaKGmJD1EnUQI/CcjhPPJRO7kmT5LAvn7WL1skV9a0kjJZQtN3o99nP8r7jSqaQMoKkPSXQMa0yWVYl7fk32v//dJJk9I5W/T9L1slbcrEUqX04xFsjnYe/MtkqPQXxbnL1+XTL5fJo0c26dLscZkDCA/tW6fD+c9cuCaJ4vtJ/deLmbmI6nX+b7RZ1gwppfTL2eWdrlOf2P/1svklVfJE5vOo/ecqlsgj3VpWlcnfr7H/0enYr0hdvnrbDHJwXD+mzzumnNe455dy+26gfYqAm7cDzXE1E6vXtmrTIbl6446ZZmN4t7qyafcxOXT8HN/sF4R5kmJwkKSdmq9duyatW7c2/XEc1atXz2SZRo8eHeZxevXqZfoavfzyy1K5cmVZvHixLFiwINSRaOGh/ZD0ONpZW7NMAwYMCFf2SktuOsotODjYKXDD83Hs70umZKGjcjKlTy49WlaT9xu/Zt++ftsR01lbl3w1+jvt6zgpn36vZy/ZKo1qlnDKUFnu3w8yHWb/+udfSeDvK1XK5JNpQ5tJkkRPHyUHhKTB/NTBzUyArgHJoeP/mABp/fYj9jbv1iplgvu1W/9bZ9FMUZu3y8nwbvXMzymdTLX/uAUyc9HmCL3ZreuXM1+XftH1ifmX5izZJkEPH0qFV3JLh4YVzR8m/1y89riT+P9W8k1FjOZlCzmU7DnR4EN/EbmaPFL7KZUoUUImTJhgOlRrMKX9gpSOTtOA6NSpU2bGa2sKAC2LaZ8eLXH1799fmjZtaj+e/vDQUXCa5VGaEdJ2OmqtcOHCZp122q5YsaL9XNpG+xNt3bpVUqZMaTp7z58/37QfP378U2fc1rdTj50vX74IT4yp/aE0YLx45YYkTuyc1QBiimTF/xtFCsQ0tuAHcv/AV6afqbt+jlu/K9bsPS0JEz37OW7fuimVCmdy67V6uhcWJMVUWpZ76aWXTMlNR9lFBEESYgOCJMRkzzNIWhsFQdJrBEnRf8btmECzYv/++6/pY6WZqFq1npzHBwAAeA6CpCiiUwNomS1Dhgxm1nCdzgAAALdhdJvb8Zs8imj/JCqXAIDnhdFt7keQBACAB9Lp/f5/ir9n3h/R/LYkAAAA0RGZJAAAPBBdktyPIAkAAE9ElOR2lNsAAABcIJMEAIAHYnSb+xEkAQDggRjd5n6U2wAAAFwgkwQAgAei37b7ESQBAOCJiJLcjnIbAACAC2SSAADwQIxucz+CJAAAPBCj29yPIAkAAA9ElyT3o08SAACAC2SSAADwRKSS3I4gCQAAD0THbfej3AYAAOACmSQAADwQo9vcjyAJAAAPRJck96PcBgAA4AJBEgAAnpxKiswSARs3bpQ333xT0qdPL15eXrJo0SKn7TabTQYOHCjp0qUTf39/qVy5shw7dsypzdWrV6VJkyaSOHFiSZo0qbRu3Vpu377t1Gb//v1StmxZ8fPzk4wZM8qoUaOeuJb58+dLnjx5TJsCBQrIsmXLInwt4UGQBACAB49ui8x/EXHnzh0pVKiQTJkyxeV2DWYmTpwo06ZNk23btkmCBAmkWrVqEhgYaG+jAdKhQ4dk1apVsmTJEhN4tWvXzr795s2bUrVqVcmcObPs2rVLRo8eLYMHD5Yvv/zS3mbz5s3SqFEjE2Dt2bNH6tSpY5aDBw9G6FrC9R7bNNxCtKAfjiRJksjFKzdMlA3ERMmKd3rRlwC4jS34gdw/8JXcuOG+n+PW74odR89LwkTPfo7bt25K8dzpnulavby8ZOHChSY4URpKaIapR48e0rNnT7NOj5smTRqZMWOGNGzYUA4fPiwBAQGyY8cOKVasmGmzYsUKqV69upw9e9bsP3XqVPnoo4/kwoUL4uPjY9r07dvXZK2OHDlinjdo0MAEbBpkWUqWLCmFCxc2QVF4riW8yCQBAODBo9sis1hBl+Ny//79CF/LqVOnTGCjZS2LBnIlSpSQLVu2mOf6VUtsVoCktL23t7fJ9lhtypUrZw+QlGaAjh49KteuXbO3cTyP1cY6T3iuJbwIkgAAiMVdkrTfjwYR1jJixIgIX8uFCxfMV83WONLn1jb9mjp1aqftcePGleTJkzu1cXUMx3M8rY3j9rCuJbyYAgAAgFg8B8CZM2ecym2+vr6Rv7YYgkwSAACxmAZIjsuzBElp06Y1Xy9evOi0Xp9b2/TrpUuXnLY/fPjQjHhzbOPqGI7neFobx+1hXUt4ESQBAOCBnvfottBkzZrVBCBr1qyxr9P+TdrXqFSpUua5fr1+/boZtWZZu3atPHr0yPQXstroiLegoCB7Gx0Jlzt3bkmWLJm9jeN5rDbWecJzLeFFkAQAgCeKbKftCMZIt2/flr1795rF6iCtj0+fPm1Gu3Xt2lU+/vhj+eWXX+TAgQPSrFkzM8rMGgGXN29eef3116Vt27ayfft22bRpk3Tq1MmMNtN2qnHjxqbTtg7v16kC5s6dKxMmTJDu3bvbr6NLly5mVNzYsWPNiDedImDnzp3mWOZtCce1hBd9kgAAQJh27twpFStWtD+3ApfmzZubofW9e/c2Q/N13iPNGL366qsmmNEJHy2zZs0ywUylSpXMqLZ69eqZ+Yws2nH8119/lY4dO0rRokUlZcqUZlJIx7mUSpcuLbNnz5b+/fvLhx9+KDlz5jRTBOTPn9/eJjzXEh7MkxSNME8SYgPmSUJM9jznSdpz/IIkisQ8Sbdu3ZSXc6R167V6OjJJAAB4Iu5w63b0SQIAAHCBTBIAAB4osiPUonJ0W0xFkAQAgAdyvLXIs+6P0FFuAwAAcIFMEgAAHoh+2+5HkAQAgCciSnI7giQAADwQHbfdjz5JAAAALpBJAgDAU6ttkRndFpUXE0MRJAEA4IHokuR+lNsAAABcIJMEAIAHYjJJ9yNIAgDAI1FwczfKbQAAAC6QSQIAwANRbnM/giQAADwQxTb3o9wGAADgApkkAAA8EOU29yNIAgDAA3HvNvcjSAIAwBPRKcnt6JMEAADgApkkAAA8EIkk9yNIAgDAA9Fx2/0otwEAALhAJgkAAA/E6Db3I0gCAMAT0SnJ7Si3AQAAuEAmCQAAD0Qiyf0IkgAA8ECMbnM/ym0AAAAukEkCAMCDx7dFZn+EjiAJAAAPRLnN/Si3AQAAuECQBAAA4ALlNgAAPBDlNvcjSAIAwANxWxL3o9wGAADgApkkAAA8EOU29yNIAgDAA3FbEvej3AYAAOACmSQAADwRqSS3I0gCAMADMbrN/Si3AQAAuEAmCQAAD8ToNvcjkwQAgAd3SYrMEhGDBw8WLy8vpyVPnjz27YGBgdKxY0dJkSKFJEyYUOrVqycXL150Osbp06elRo0aEj9+fEmdOrX06tVLHj586NRm/fr1UqRIEfH19ZUcOXLIjBkznriWKVOmSJYsWcTPz09KlCgh27dvF3cgSAIAwBM97yhJRPLlyyfnz5+3L7///rt9W7du3WTx4sUyf/582bBhg5w7d07q1q1r3x4cHGwCpAcPHsjmzZtl5syZJgAaOHCgvc2pU6dMm4oVK8revXula9eu0qZNG1m5cqW9zdy5c6V79+4yaNAg2b17txQqVEiqVasmly5dkqjmZbPZbFF+VDyTmzdvSpIkSeTilRuSOHFi3kXESMmKd3rRlwC4jS34gdw/8JXcuOG+n+PW74rz/16P1Dn0OOlSJg33tQ4ePFgWLVpkgpeQ9BipUqWS2bNnS/369c26I0eOSN68eWXLli1SsmRJWb58udSsWdMET2nSpDFtpk2bJn369JHLly+Lj4+Pebx06VI5ePCg/dgNGzaU69evy4oVK8xzzRwVL15cJk+ebJ4/evRIMmbMKJ07d5a+fftKVCKTBACAB49ui8x/EXXs2DFJnz69ZMuWTZo0aWLKZ2rXrl0SFBQklStXtrfVUlymTJlMkKT0a4ECBewBktIMkAZrhw4dsrdxPIbVxjqGZqH0XI5tvL29zXOrTVSi4zYAALG447YGKY60L5AuIWkGR8tjuXPnNqW2IUOGSNmyZU3W58KFCyYTlDRpUqd9NCDSbUq/OgZI1nZrW2ht9Brv3bsn165dM2U7V200cxXVCJKiEavyeSvEBxaIaeUIIKZ/vp9HT5aQwc2z7q+lKkfa10dLayG98cYb9scFCxY0QVPmzJll3rx54u/vLzERQVI0cuvWLfM1R1bnDywAwPN+nmu/IXfQjE3atGklZxT8rtDj7Nu3z4wSs7jKIrmiWaNcuXLJ8ePHpUqVKqYUpn2HHLNJOrpNz6H0a8hRaNboN8c2IUfE6XPtM6WBWJw4ccziqo11jKhEkBSNaJ33zJkzkihRIjO0Eu6nf0npX1H6vtNZHjENn+/nTzNIGiDpz3N30YBGR4FpUBIVAZdjgBQRt2/flhMnTkjTpk2laNGiEi9ePFmzZo0Z+q+OHj1q+iyVKlXKPNevw4cPN6PQdPi/WrVqlfnZGxAQYG+zbNkyp/NoG+sYer16Lj1PnTp17B239XmnTm4YFKKj24DY6saNG5oTN1+BmIbPN6JSjx49bOvXr7edOnXKtmnTJlvlypVtKVOmtF26dMlsb9++vS1Tpky2tWvX2nbu3GkrVaqUWSwPHz605c+f31a1alXb3r17bStWrLClSpXK1q9fP3ubkydP2uLHj2/r1auX7fDhw7YpU6bY4sSJY9pafvjhB5uvr69txowZtj/++MPWrl07W9KkSW0XLlyI8m84QRJiNX6JICbj842o1KBBA1u6dOlsPj4+tpdeesk8P378uH37vXv3bO+//74tWbJkJtB56623bOfPn3c6xl9//WV74403bP7+/ibA0sArKCjIqc26detshQsXNufJli2bbfr06U9cy6RJk0xApm1eeeUV29atW93yzWaeJMRq1nwj7pzTBHhR+HwDkcM8SYjVtIOijuQIb0dFwJPw+QYih0wSAACAC2SSAAAAXCBIAgAAcIEgCQAAwAWCJMAN1q9fbyYE1dlngZgiS5YsMn78+Bd9GcBzQ5CEaK9FixYm4Bg5cqTT+kWLFjEzOTyS3q1cb61Qo0aNF30pAEJBkASPoNPmf/rpp+YO0FElKqb0B57FN998I507d5aNGzfKuXPneBOBaIogCR6hcuXK5uaFI0aMeGqbn376SfLly2fmhtGywNixY52267phw4ZJs2bNzMSR7dq1kxkzZpibMS5ZskRy584t8ePHl/r168vdu3dl5syZZp9kyZLJBx98IMHBwfZjfffdd1KsWDFznz29rsaNG5v7EQHhud/V3LlzpUOHDiaTpJ/BkGVavQ+Vfr7081i6dGlzDyxHU6dOlezZs5v7WOnnVj+PjvQYX3zxhdSsWdMcI2/evCZ7pTcirVChgiRIkMAcV++7ZdHHtWvXljRp0kjChAmlePHisnr16qe+jlatWpnjOwoKCjL35NIgEIgR3DKPNxCFmjdvbqtdu7ZtwYIFNj8/P9uZM2fM+oULF5r7rim9T5C3t7dt6NChtqNHj5pp7HXae8fp7DNnzmxLnDixbcyYMWYqfV10e7x48WxVqlSx7d6927ZhwwZbihQpzL2F3nnnHduhQ4dsixcvNlPf6/2CLN98841t2bJlthMnTti2bNli7k+kU+07Tquv13bt2jU+C3Cin51ixYqZx/rZyp49u+3Ro0dOn5sSJUqYe2Tp569s2bK20qVL2/fXfwf6mdV7WulnfezYsebeVnq/LIseQ28bMXfuXNOmTp06tixZsthee+01cw8svd9VyZIlba+//rp9H72X1rRp02wHDhyw/fnnn7b+/fubf29///2307+hcePGmcd67y4977lz55yuLUGCBLZbt27xXUeMQJAEjwmSlP5gb9Wq1RNBUuPGjU2g40hvkBgQEOD0A15/WTjSIEmP4Xj/offee8/cd8jxB321atXM+qfZsWOHOY61D0ESnkYDnvHjx5vHes8qvX+Vfl4cPzerV6+2t1+6dKlZp/fFsvZv27at0zHffvttW/Xq1e3Ptb0GORYN5HWdBmiWOXPmmCAoNPny5TP3yHIVJCn99/Xpp5/an7/55pu2Fi1a8M1HjEG5DR5F+yVpGezw4cNO6/V5mTJlnNbp82PHjjmVybSEEZKWI7R0YdFyg5bZtOTguM6xnLZr1y558803JVOmTKbkVr58ebP+9OnTUfRKERNp2Wz79u3SqFEj8zxu3LjSoEGDJ8pTBQsWtD9Oly6d+Wp9/p72WQ/5b8LxGPr5VQUKFHBaFxgYaO7vZpUBe/bsaUpzWoLWz78eM7TPdJs2bWT69Onm8cWLF2X58uWmDAfEFARJ8CjlypWTatWqSb9+/Z5pf+2LEVK8ePGe6M/hat2jR4/M4zt37phr0H5Ns2bNkh07dsjChQvNNjqDIzQaDD18+FDSp09vAiRdtH+R9qfTmyy7+kzqZ09Zn7/wcnWM0I6rAZJ+jj/55BP57bffZO/evSaoCu0zrf37Tp48afo7ff/995I1a1YpW7YsHwLEGHFf9AUAEaVTARQuXNh0WLXoX7+bNm1yaqfPc+XKZYZaR6UjR47IlStXzHVkzJjRrNu5c2eUngMxjwZH3377rRlQULVqVadtderUkTlz5kiePHnCPI71WW/evLl9nT4PCAiI1PXpMXS6jbfeesueWfrrr79C3SdFihTm2jWbpIFSy5YtI3UNQHRDkASPo3/dNmnSRCZOnGhf16NHDzMaR0evaflCf2BPnjxZPv/88yg/v5bYdFTRpEmTpH379nLw4EFzXiA0OoJSp7Bo3bq1JEmSxGlbvXr1TJZp9OjRYb6JvXr1knfeeUdefvllM+pz8eLFsmDBglBHooVHzpw5zXG0jKxZpgEDBoQre6UlNx3lpmVtx8ANiAkot8EjDR061OkHeJEiRWTevHnyww8/SP78+WXgwIGmjf5lHNVSpUplhm3Pnz/f/PWuGaUxY8ZE+XkQs2gQpEFNyADJCpI0G7l///4wj6OZmwkTJpjPnE55oUP9NZOjQ/sj47PPPjPTXejUABooaUlZ/12FRV+T9pvS9lpGBGISL+29/aIvAgDgmbQs99JLL5lArW7dui/6coAoRbkNABBhmsn9999/TR8rHQ1Xq1Yt3kXEOARJAIAI06kBdDRbhgwZTPlZR+oBMQ3lNgAAABfouA0AAOACQRIAAIALBEkAAAAuECQBAAC4QJAEwIlOwKkTFlp0ksKuXbs+93dp/fr1Zubn69evP7WNbl+0aFG4jzl48GBzS5vI0Ft16Hn13mYAYjaCJMBDAhf9xayL3hIlR44cZkZxvR+Yu+mtKsJ725XwBDYA4CmY2ALwEK+//rqZ1fj+/fuybNky6dixo7mre79+/Z5oq3du12AqKiRPnjxKjgMAnoZMEuAhfH19JW3atJI5c2bp0KGDuWfWL7/84lQiGz58uLl/Vu7cuc36M2fOmJuh6ozIGuzUrl3b6c7uelPS7t27m+16R/fevXtLyDsVhSy3aZDWp08fyZgxo7kmzWrpfcn0uBUrVjRt9B5gmlGy7p2nszOPGDHCTD7o7+8vhQoVkh9//NHpPBr45cqVy2zX44R1B3pX9Lr0GPHjx5ds2bKZm7QGBQU90U7vd6bXr+30/blx44bT9q+//lry5s0rfn5+kidPHrfcKBlA9EeQBHgoDSY0Y2RZs2aNHD16VFatWmXuOK/Bgd50NFGiRPLbb7/Jpk2bJGHChCYjZe2nt5TQ2ZL/97//ye+//y5Xr16VhQsXhnreZs2ayZw5c2TixIly+PBhE3DocTXo+Omnn0wbvY7z58+bG7EqDZC+/fZbmTZtmhw6dEi6desm7777rmzYsMEezOl9v/TGqtrXR+8s37dv3wi/J/pa9fX88ccf5txfffWVjBs3zqnN8ePHzc2QFy9eLCtWrJA9e/bI+++/b98+a9Ysc4NkDTj19X3yyScm2Jo5c2aErweAh9Mb3AKI3po3b26rXbu2efzo0SPbqlWrbL6+vraePXvat6dJk8Z2//59+z7fffedLXfu3Ka9Rbf7+/vbVq5caZ6nS5fONmrUKPv2oKAgW4YMGeznUuXLl7d16dLFPD569Kimmcz5XVm3bp3Zfu3aNfu6wMBAW/z48W2bN292atu6dWtbo0aNzON+/frZAgICnLb36dPniWOFpNsXLlz41O2jR4+2FS1a1P580KBBtjhx4tjOnj1rX7d8+XKbt7e37fz58+Z59uzZbbNnz3Y6zrBhw2ylSpUyj0+dOmXOu2fPnqeeF0DMQJ8kwENodkgzNpoh0vJV48aNzWgtS4ECBZz6Ie3bt89kTTS74igwMFBOnDhhSkya7SlRooR9m95/q1ixYk+U3Cya5YkTJ46UL18+3Net13D37l2pUqWK03rNZr388svmsWZsHK9DlSpVSiJq7ty5JsOlr0/vTq8d2xMnTuzUJlOmTOau9Y7n0fdTs1/6Xum+rVu3lrZt29rb6HGSJEkS4esB4NkIkgAPof10pk6dagIh7XcU8oaiCRIkcHquQULRokVN+SikVKlSPXOJL6L0OtTSpUudghOlfZqiypYtW6RJkyYyZMgQU2bUoOaHH34wJcWIXquW6UIGbRocAohdCJIAD6FBkHaSDq8iRYqYzErq1KmfyKZY0qVLJ9u2bZNy5crZMya7du0y+7qi2SrNumhfIu04HpKVydIO4ZaAgAATDOld45+WgdJO0lYndMvWrVslIjZv3mw6tX/00Uf2dX///fcT7fQ6zp07ZwJN6zze3t6ms3uaNGnM+pMnT5qAC0DsRsdtIIbSX/IpU6Y0I9q04/apU6fMPEYffPCBnD171rTp0qWLjBw50kzIeOTIEdOBObQ5jrJkySLNmzeXVq1amX2sY2pHaKVBio5q09Lg5cuXTWZGS1g9e/Y0nbW187OWs3bv3i2TJk2yd4Zu3769HDt2THr16mXKXrNnzzYdsCMiZ86cJgDS7JGeQ8turjqh64g1fQ1ajtT3Rd8PHeGmIweVZqK0o7nu/+eff8qBAwfM1AufffZZhK4HgOcjSAJiKB3evnHjRtMHR0eOabZG+9ponyQrs9SjRw9p2rSpCRq0b44GNG+99Vaox9WSX/369U1ApcPjte/OnTt3zDYtp2mQoSPTNCvTqVMns14no9QRYhp86HXoCDstv+mUAEqvUUfGaeCl0wPoKDgdVRYRtWrVMoGYnlNn1dbMkp4zJM3G6ftRvXp1qVq1qhQsWNBpiL+OrNMpADQw0syZZr80YLOuFUDs4aW9t1/0RQAAAEQ3ZJIAAABcIEgCAABwgSAJAADABYIkAAAAFwiSAAAAXCBIAgAAcIEgCQAAwAWCJAAAABcIkgAAAFwgSAIAAHCBIAkAAMAFgiQAAAB50v8BuSm9QJOosZwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Anomaly\"])\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')  \n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f9a833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# import os\n",
    "\n",
    "# project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "# models_path = os.path.join(project_root, \"Models\")\n",
    "# os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "# joblib.dump(autoencoder, os.path.join(models_path, \"autoencoder.pkl\"))\n",
    "# joblib.dump(best_threshold, os.path.join(models_path, \"ae_threshold.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b1600cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Graduation Project\\\\Models\\\\ae_val_scores.pkl']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# project_root = r\"C:/Graduation Project/AI_Cybersecurity\"\n",
    "# models_path = os.path.join(project_root, \"Models\")\n",
    "# os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "models_path = os.path.join(project_root, \"Models\")\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "# ----------------------------------\n",
    "# 1️ Predict (Reconstruction)\n",
    "# ----------------------------------\n",
    "X_test_recon = autoencoder.predict(x_test, verbose=0)  # تم تعديل الاسم هنا\n",
    "\n",
    "# ----------------------------------\n",
    "# 2️ Reconstruction Error (IMPORTANT)\n",
    "# ----------------------------------\n",
    "recon_error = np.mean(\n",
    "    np.square(x_test - X_test_recon),  # تم تعديل الاسم هنا\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ----------------------------------\n",
    "# 3️ Save NumPy artifacts ONLY\n",
    "# ----------------------------------\n",
    "joblib.dump(\n",
    "    recon_error,\n",
    "    os.path.join(models_path, \"ae_preds.pkl\")   # numbers only\n",
    ")\n",
    "\n",
    "joblib.dump(\n",
    "    best_threshold,\n",
    "    os.path.join(models_path, \"ae_threshold.pkl\")\n",
    ")\n",
    "\n",
    "# ----------------------------------\n",
    "# 4️ Save model separately \n",
    "# ----------------------------------\n",
    "autoencoder.save(\n",
    "    os.path.join(models_path, \"autoencoder.keras\")\n",
    ")\n",
    "\n",
    "\n",
    "# Predict reconstructed outputs\n",
    "# -------------------------------\n",
    "train_pred = autoencoder.predict(x_train, verbose=0)\n",
    "val_pred   = autoencoder.predict(x_val, verbose=0)\n",
    "\n",
    "# -------------------------------\n",
    "# Compute reconstruction error\n",
    "# -------------------------------\n",
    "train_mse = np.mean(np.square(x_train - train_pred), axis=1)\n",
    "val_mse   = np.mean(np.square(x_val - val_pred), axis=1)\n",
    "\n",
    "# -------------------------------\n",
    "# Save reconstruction errors\n",
    "# -------------------------------\n",
    "joblib.dump(train_mse, os.path.join(models_path, \"ae_train_scores.pkl\"))\n",
    "joblib.dump(val_mse, os.path.join(models_path, \"ae_val_scores.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
