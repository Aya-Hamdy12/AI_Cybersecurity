{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843b27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib, json, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d2ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1638568, 50), (409643, 50), (834347, 50))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the saved preprocessed data\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "processed_path = os.path.join(project_root, \"Data\", \"Processed\")\n",
    "\n",
    "x_train = joblib.load(os.path.join(processed_path, \"train_scaled.pkl\"))\n",
    "x_val = joblib.load(os.path.join(processed_path, \"val_scaled.pkl\"))\n",
    "x_test = joblib.load(os.path.join(processed_path, \"test_scaled.pkl\"))\n",
    "y_test = joblib.load(os.path.join(processed_path, \"test_labels.pkl\"))\n",
    "\n",
    "\n",
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec702291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scaler so that any new \n",
    "# traffic data (later) will be scaled \n",
    "# the exact same way as the trained data\n",
    "\n",
    "scaler_path = os.path.join(processed_path, \"scaler_cicids.pkl\")\n",
    "\n",
    "if os.path.exists(scaler_path):\n",
    "    scaler = joblib.load(scaler_path)\n",
    "else:\n",
    "    scaler = None\n",
    "    print(\"scaler not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfecdaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ae_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bottleneck_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ae_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ae_input (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_32 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_16 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ enc_dense_12 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m204\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bottleneck_16 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_12 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m204\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_16 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dec_dense_32 (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ae_output (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m1,650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,178</span> (20.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,178\u001b[0m (20.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,178</span> (20.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,178\u001b[0m (20.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BUILD THE AUTOENCODER\n",
    "\n",
    "# ensure same results every time\n",
    "seed = 55\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "\n",
    "\n",
    "input_dim = 50  # one input neuron for each feature\n",
    "\n",
    "input_layer = Input(shape=(input_dim,), name=\"ae_input\")   #entry point\n",
    "\n",
    "# ENCODER (compression)\n",
    "enc = Dense(32, activation='relu' , name=\"enc_dense_32\")(input_layer)    \n",
    "enc = Dense(16, activation='relu' , name=\"enc_dense_16\")(enc)\n",
    "enc = Dense(12, activation='relu' , name=\"enc_dense_12\")(enc)\n",
    "bottleneck = Dense(16, activation='relu' , name=\"bottleneck_16\")(enc)\n",
    "# each layer takes the previous layer's output and transforms it to a smaller number of neurons\n",
    "# ,this compresses the information\n",
    "# ,the final layer is the compressed version the encoder learns to use for reconstructing the data\n",
    "\n",
    "\n",
    "# DECODER (reconstruction)\n",
    "dec = Dense(12, activation='relu' , name=\"dec_dense_12\")(bottleneck)\n",
    "dec = Dense(16, activation='relu', name=\"dec_dense_16\")(dec)\n",
    "dec = Dense(32, activation='relu', name=\"dec_dense_32\")(dec)\n",
    "\n",
    "# these layers start reconstructing the data back to the original 50 dimension\n",
    "# basically the encoder extracts patterns, decoder just rebuilds\n",
    "\n",
    "output_layer = Dense(input_dim, activation='linear', name=\"ae_output\")(dec)\n",
    "\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer, name=\"Autoencoder\")\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30481a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.1847 - val_loss: 0.0715\n",
      "Epoch 2/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0572 - val_loss: 0.0475\n",
      "Epoch 3/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0427 - val_loss: 0.0391\n",
      "Epoch 4/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0365 - val_loss: 0.0342\n",
      "Epoch 5/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 6/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0293 - val_loss: 0.0281\n",
      "Epoch 7/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0270 - val_loss: 0.0260\n",
      "Epoch 8/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0250 - val_loss: 0.0242\n",
      "Epoch 9/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0234 - val_loss: 0.0227\n",
      "Epoch 10/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0220 - val_loss: 0.0215\n",
      "Epoch 11/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0210 - val_loss: 0.0206\n",
      "Epoch 12/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0202 - val_loss: 0.0198\n",
      "Epoch 13/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 14/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0188 - val_loss: 0.0186\n",
      "Epoch 15/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0184 - val_loss: 0.0182\n",
      "Epoch 16/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0179 - val_loss: 0.0178\n",
      "Epoch 17/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 18/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 19/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 20/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0167 - val_loss: 0.0166\n",
      "Epoch 21/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 22/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0162 - val_loss: 0.0161\n",
      "Epoch 23/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0159 - val_loss: 0.0159\n",
      "Epoch 24/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0157 - val_loss: 0.0157\n",
      "Epoch 25/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 26/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 27/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 28/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 29/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 30/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 31/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 32/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 33/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 34/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 35/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 36/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0137 - val_loss: 0.0138\n",
      "Epoch 37/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0137\n",
      "Epoch 38/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 39/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 40/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 41/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 42/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 43/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 44/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 45/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 46/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 47/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0129 - val_loss: 0.0130\n",
      "Epoch 48/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0128\n",
      "Epoch 49/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 50/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 51/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 52/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 53/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 54/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 55/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 56/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 57/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0120 - val_loss: 0.0121\n",
      "Epoch 58/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 59/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 60/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 61/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 62/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 63/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 64/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 65/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 66/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 67/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 68/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 69/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 70/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 71/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 72/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 73/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 74/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 75/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 76/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 77/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 78/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 79/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 80/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 81/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 82/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 83/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 84/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 85/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 86/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 87/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 88/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 89/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 90/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 91/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 92/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 93/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 94/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 95/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 96/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 97/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 98/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 99/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 100/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 101/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 102/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 103/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 104/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 105/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 106/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 107/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 108/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 109/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 110/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 111/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 112/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 113/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 114/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 115/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 116/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 117/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 118/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 119/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 120/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 121/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 122/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 123/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 124/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 125/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 126/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 127/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 128/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 129/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 130/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 131/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 132/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 133/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 134/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 135/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 136/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 137/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 138/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 139/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 140/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 141/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 142/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 143/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 144/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 145/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 146/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 147/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 148/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 149/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 150/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 151/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 152/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 153/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 154/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 155/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 156/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 157/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 158/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 159/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 160/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 161/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 162/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 163/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 164/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 165/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 166/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 167/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 168/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 169/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 170/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 171/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 172/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 173/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 174/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 175/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 176/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 177/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 178/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 179/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 180/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 181/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 182/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 183/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 184/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 185/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 186/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 187/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 188/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 189/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 190/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 191/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 192/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 193/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 194/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 195/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 196/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 197/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 198/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 199/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 200/200\n",
      "\u001b[1m6401/6401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Restoring model weights from the end of the best epoch: 200.\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE AUTOENCODER\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    x_train, x_train,       # input = output bec autoencoder tries to reconstruct\n",
    "    epochs=200,              # number of times the model sees all data\n",
    "    batch_size=256,\n",
    "    validation_data=(x_val, x_val),  #check reconstruction on validation set (no attacks)\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    "    # shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4218901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51206/51206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1ms/step\n",
      "\u001b[1m12802/12802\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# reconstruction error = how much the autoencoder failed to recreate the input\n",
    "\n",
    "# get reconstructed outputs\n",
    "train_pred = autoencoder.predict(x_train)\n",
    "val_pred = autoencoder.predict(x_val)\n",
    "\n",
    "# compute reconstruction error\n",
    "train_mse = np.mean(np.square(x_train - train_pred), axis=1)\n",
    "val_mse = np.mean(np.square(x_val - val_pred), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e07593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26074/26074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.00024352, 0.0251422 , 0.00408921, 0.00058571, 0.02001495,\n",
       "        0.00514625, 0.00268333, 0.00113993, 0.04336171, 0.00125575]),\n",
       " array([0.0002007 , 0.00103877, 0.00027409, 0.00017998, 0.00428127,\n",
       "        0.00027761, 0.00042772, 0.01397311, 0.0002904 , 0.00290323]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on traffic with anomalies\n",
    "# low error = normal behavior it understands\n",
    "# high error = unusual behavior = anomaly\n",
    "\n",
    "test_pred = autoencoder.predict(x_test)     # get reconstructed output of x+test\n",
    "\n",
    "test_mse = np.mean(np.square(x_test - test_pred), axis=1)\n",
    "\n",
    "train_mse[:10] , test_mse[:10]   #just to see examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb2ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.017731424796764296\n"
     ]
    }
   ],
   "source": [
    "# set anomaly threshold \n",
    "# and decide which reconstruction errors indicate anomalies\n",
    "# We want to decide which error value counts as an anomaly.\n",
    "\n",
    "\n",
    "best_threshold = np.percentile(val_mse, 88)  # top % of reconstruction error\n",
    "\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "# print(\"Best F1:\", best_f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e86b97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies detected: 464402\n",
      "Actual number of anomalies: 424704.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = (test_mse > best_threshold).astype(int)\n",
    "print(\"Number of anomalies detected:\", np.sum(y_pred))\n",
    "print(\"Actual number of anomalies:\", np.sum(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81743cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.92974385956922\n",
      "Precision:  0.8941477426884467\n",
      "Recall:  0.9777256630500302\n",
      "F1-score;  0.9340708531941073\n",
      "Confusion matrix:\n",
      " [[360485  49158]\n",
      " [  9460 415244]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)     #how many of the detected anomalies were actually attacks\n",
    "print(\"Recall: \", recall)           #how many actual attacks were caught\n",
    "print(\"F1-score; \", f1)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bfe2820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Anomaly\"])\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')  \n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f9a833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# import os\n",
    "\n",
    "# project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "# models_path = os.path.join(project_root, \"Models\")\n",
    "# os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "# joblib.dump(autoencoder, os.path.join(models_path, \"autoencoder.pkl\"))\n",
    "# joblib.dump(best_threshold, os.path.join(models_path, \"ae_threshold.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1600cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\Nourhan\\\\Documents\\\\Graduation Project\\\\AI_Cybersecurity-main\\\\Models\\\\ae_val_scores.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "models_path = os.path.join(project_root, \"Models\")\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "X_test_recon = autoencoder.predict(x_test, verbose=0)\n",
    "\n",
    "\n",
    "recon_error = np.mean(\n",
    "    np.square(x_test - X_test_recon),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "joblib.dump(\n",
    "    recon_error,\n",
    "    os.path.join(models_path, \"ae_preds.pkl\")  \n",
    ")\n",
    "\n",
    "joblib.dump(\n",
    "    best_threshold,\n",
    "    os.path.join(models_path, \"ae_threshold.pkl\")\n",
    ")\n",
    "\n",
    "\n",
    "autoencoder.save(\n",
    "    os.path.join(models_path, \"autoencoder.keras\")\n",
    ")\n",
    "\n",
    "\n",
    "train_pred = autoencoder.predict(x_train, verbose=0)\n",
    "val_pred   = autoencoder.predict(x_val, verbose=0)\n",
    "\n",
    "train_mse = np.mean(np.square(x_train - train_pred), axis=1)\n",
    "val_mse   = np.mean(np.square(x_val - val_pred), axis=1)\n",
    "\n",
    "\n",
    "joblib.dump(train_mse, os.path.join(models_path, \"ae_train_scores.pkl\"))\n",
    "joblib.dump(val_mse, os.path.join(models_path, \"ae_val_scores.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
